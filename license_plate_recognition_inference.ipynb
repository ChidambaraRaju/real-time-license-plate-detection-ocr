{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "p4CXT97McgUn"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import easyocr\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tYlksm9kdPEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loading the Detection Transformer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# 2. Load Model and Processor\n",
        "model_id = \"justjuu/rtdetr-v2-license-plate-detection\"\n",
        "processor = AutoImageProcessor.from_pretrained(model_id, use_fast = True)\n",
        "model = AutoModelForObjectDetection.from_pretrained(model_id)\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ITzpgzAodM3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loading the OCR\n",
        "reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "uTmMhyVin1XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function to extract License Plate Number\n",
        "import easyocr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_license_plate_text(image, box):\n",
        "\n",
        "    x1, y1, x2, y2 = map(int, box.tolist())\n",
        "\n",
        "    # Get image dimensions to avoid cropping outside the image\n",
        "    img_w, img_h = image.size\n",
        "\n",
        "    # --- IMPROVEMENT: Add 5% Padding ---\n",
        "    pad_w = (x2 - x1) * 0.05\n",
        "    pad_h = (y2 - y1) * 0.05\n",
        "\n",
        "    # Apply padding and ensure we don't go < 0 or > image size (Clamping)\n",
        "    crop_x1 = max(0, int(x1 - pad_w))\n",
        "    crop_y1 = max(0, int(y1 - pad_h))\n",
        "    crop_x2 = min(img_w, int(x2 + pad_w))\n",
        "    crop_y2 = min(img_h, int(y2 + pad_h))\n",
        "\n",
        "    # Crop with padding\n",
        "    plate_crop = image.crop((crop_x1, crop_y1, crop_x2, crop_y2))\n",
        "\n",
        "    # Convert PIL Image to numpy array for EasyOCR\n",
        "    plate_crop_np = np.array(plate_crop)\n",
        "\n",
        "    # 1. OCR Inference\n",
        "    # allowlist: restricts detection to Uppercase A-Z and 0-9 (perfect for plates)\n",
        "    results = reader.readtext(\n",
        "        plate_crop_np,\n",
        "        allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 ',\n",
        "        canvas_size=512,\n",
        "    )\n",
        "\n",
        "    # 2. Extract best result\n",
        "    # EasyOCR returns a list of tuples: (bbox, text, confidence)\n",
        "    if not results:\n",
        "        return None\n",
        "    elif len(results) == 1:\n",
        "        return results[0][1]\n",
        "    else:\n",
        "      word = []\n",
        "      for result in results:\n",
        "        word.append(result[1])\n",
        "      return \" \".join(word)"
      ],
      "metadata": {
        "id": "CZsOVZbbfFkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Function to Plot the Bounding Box along with License Plate Number\n",
        "def plot_predictions_with_ocr(results, images):\n",
        "    for result, image in zip(results, images):\n",
        "        fig, ax = plt.subplots(1, figsize=(8, 8))\n",
        "        ax.imshow(image)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        for score, label, box in zip(\n",
        "            result[\"scores\"], result[\"labels\"], result[\"boxes\"]\n",
        "        ):\n",
        "            # Draw bounding box\n",
        "            x1, y1, x2, y2 = box.tolist()\n",
        "            w, h = x2 - x1, y2 - y1\n",
        "\n",
        "            rect = patches.Rectangle(\n",
        "                (x1, y1), w, h,\n",
        "                linewidth=2,\n",
        "                edgecolor=\"green\",\n",
        "                facecolor=\"none\"\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "            # ðŸ”¥ OCR extraction\n",
        "            plate_text = extract_license_plate_text(image, box)\n",
        "\n",
        "            # Display label + OCR text\n",
        "            caption = f\"{plate_text} ({score:.2f})\"\n",
        "\n",
        "            ax.text(\n",
        "                x1,\n",
        "                y1 - 8,\n",
        "                caption,\n",
        "                color=\"white\",\n",
        "                fontsize=10,\n",
        "                bbox=dict(facecolor=\"black\", alpha=0.6, pad=2)\n",
        "            )"
      ],
      "metadata": {
        "id": "prp2XZToeLCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inference Pipeline\n",
        "image = Image.open(\"./Screenshot (192).png\").convert(\"RGB\")\n",
        "\n",
        "# Pre processing\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "# Move inputs to the same device as the model\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "# Inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Post-process (Non-Maximum Suppression is effectively handled by the DETR architecture, but we define thresholds)\n",
        "target_sizes = torch.tensor([image.size[::-1]]).to(device)\n",
        "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.5)\n",
        "\n",
        "plot_predictions_with_ocr(results, [image])"
      ],
      "metadata": {
        "id": "NhmseGYucnCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZbX6yWWuy4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}